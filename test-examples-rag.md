make test-examples-rag

ğŸ¤– [36mRAG Conversation System Examples[0m
[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m

[33mPrerequisites:[0m
  1. ekoDB server running (make run in ekodb/)
  2. OPENAI_API_KEY set in server environment
  3. API_BASE_URL and API_BASE_KEY exported in your shell

[36mBuilding Rust client library...[0m
âœ“ Rust client built

[36mBuilding Python client bindings...[0m
ğŸ¹ Building a mixed python/rust project
ğŸ”— Found pyo3 bindings with abi3 support
ğŸ Not using a specific python interpreter
ğŸ’» Using `MACOSX_DEPLOYMENT_TARGET=11.0` for aarch64-apple-darwin by default
ğŸ“¦ Built wheel for abi3 Python â‰¥ 3.8 to /Users/tek/Development/ekoDB/ekodb-client/ekodb-client-py/target/wheels/ekodb_client-0.6.0-cp38-abi3-macosx_11_0_arm64.whl
âœ“ Python client built and installed

[36mBuilding TypeScript client library...[0m
âœ“ TypeScript client built

[36mInstalling TypeScript client in examples...[0m
âœ“ TypeScript client installed

[36mBuilding TypeScript example...[0m
âœ“ TypeScript example built

[36mBuilding Go client library...[0m
âœ“ Go client built

[36mBuilding Go RAG example...[0m
âœ“ Go example built

[36mBuilding Kotlin client library...[0m
âœ“ Kotlin client built

[36mBuilding Kotlin RAG example...[0m
âœ“ Kotlin example built

[36mRunning Rust RAG Example...[0m
[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m
=== ekoDB RAG Conversation System ===

This example shows how ekoDB can power a self-improving AI system
that learns from its own conversation history.

=== Step 1: Building Conversation History ===
Storing previous conversations with embeddings...

  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 34 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 346.90875ms
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 169 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 567.017583ms
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 33 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 702.5135ms
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 230 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 338.637417ms
    â€¢ Function auto-cleaned up by client
âœ“ Stored Rust programming conversation (4 messages)
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 31 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 563.118125ms
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 217 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 319.73825ms
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 33 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 260.7315ms
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 232 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 514.3135ms
    â€¢ Function auto-cleaned up by client
âœ“ Stored database design conversation (4 messages)
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 36 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 478.358333ms
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 178 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 284.398959ms
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 37 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 436.230292ms
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 213 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 356.09ms
    â€¢ Function auto-cleaned up by client
âœ“ Stored performance optimization conversation (4 messages)

=== Step 2: New User Question with Context Retrieval ===
User asks: "How do I write memory-safe high-performance database code?"

=== Step 3: Searching Related Context ===
Using hybrid search to find relevant messages from all conversations...


â†’ Generating embedding for user question...
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 58 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 268.071584ms
    â€¢ Function auto-cleaned up by client

â†’ Executing hybrid_search()...
  â€¢ Collection: rag_messages
  â€¢ Query text: "How do I write memory-safe high-performance database code?"
  â€¢ Vector dimensions: 1536
  â€¢ Limit: 5 results
  â€¢ Search type: Semantic (vector) + Keyword (text)
  â€¢ Server combines both scores for relevance ranking
  âœ“ Search completed in 109.077583ms

âœ“ Found 5 related messages across all conversations:
  1. From conv_database_design
     Use NoSQL when you need: flexible schemas, horizontal scaling, high write throughput, or when working with unstructured data. SQL is better for complex queries, ACID transactions, and structured data with well-defined relationships.

  2. From conv_database_design
     What is database normalization?

  3. From conv_database_design
     Database normalization is the process of organizing data to reduce redundancy and improve data integrity. It involves dividing large tables into smaller ones and defining relationships between them using foreign keys.

  4. From conv_database_design
     When should I use NoSQL over SQL?

  5. From conv_performance
     How can I optimize database queries?

=== Step 4: Generating Context-Aware Response ===
âœ“ AI Response (with context from 3 conversations):

Writing memory-safe, high-performance database code involves several practices, such as:

1. **Choose the appropriate database**: Depending on your need, choose between SQL and NoSQL. As mentioned in Context 1 and 4, NoSQL is more suitable for flexible schemas, horizontal scaling, high write throughput, and unstructured data. SQL is better for complex queries, ACID transactions, and structured data with well-defined relationships.

2. **Database Normalization**: As explained in Context 2 and 3, database normalization can reduce redundancy and improve data integrity. It can lead to more efficient memory usage as data is not unnecessarily duplicated.

3. **Optimize Queries**: When it comes to optimizing database queries, make sure to limit the amount of data that gets returned from a query by using the SELECT statement effectively. Avoid using "SELECT *". Also, use JOINs effectively and avoid unnecessary subqueries. Make use of indexes where possible, but don't over-index as it may lead to slower write operations.

4. **Use Prepared Statements**: Prepared statements or parameterized queries are a way of executing SQL statements with parameters that help prevent SQL injection attacks. They also allow the database to cache the queries for improved performance.

5. **Connection and Memory Management**: Ensure to close database connections when not in use. Also, pay attention to managing the memory resources efficiently. For instance, avoid loading large amounts of data into memory at once, process data in chunks if possible.

6. **Concurrency Control**: Implement proper concurrency control mechanisms to ensure data integrity and consistency when multiple processes are interacting with the database concurrently.

7. **Profiling and monitoring**: Regularly profile your database and monitor the performance. This can help you identify potential bottlenecks and areas for improvement.

As always, the specific techniques and strategies you use will depend on your specific use case, the database system you're using, and the nature of your data and queries.

=== Step 5: Storing New Conversation ===
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 58 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 305.273292ms
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 2079 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 235.052416ms
    â€¢ Function auto-cleaned up by client
âœ“ New conversation stored and indexed for future retrieval

=== Step 6: Cross-Conversation Search ===
Searching for messages about 'ownership' across ALL conversations...


â†’ Executing text_search()...
  â€¢ Collection: rag_messages
  â€¢ Query: "ownership system"
  â€¢ Limit: 3 results
  â€¢ Search method: Full-text with fuzzy matching & stemming
  â€¢ No vector embeddings needed - pure keyword search
  âœ“ Text search completed in 65.87ms

âœ“ Found 3 messages mentioning ownership:
  1. From conv_rust_programming: Rust's key features include: memory safety without garbage collection, zero-cost abstractions, ownership system, powerful type system, and excellent concurrency support.

  2. From conv_performance: Rust's ownership system provides zero-cost memory management. Use Box for heap allocation, Rc/Arc for shared ownership, and avoid cloning large data structures. The compiler optimizes away unnecessary allocations.

  3. From conv_new_question: Writing memory-safe, high-performance database code involves several practices, such as:

1. **Choose the appropriate database**: Depending on your need, choose between SQL and NoSQL. As mentioned in Context 1 and 4, NoSQL is more suitable for flexible schemas, horizontal scaling, high write throughput, and unstructured data. SQL is better for complex queries, ACID transactions, and structured data with well-defined relationships.

2. **Database Normalization**: As explained in Context 2 and 3, database normalization can reduce redundancy and improve data integrity. It can lead to more efficient memory usage as data is not unnecessarily duplicated.

3. **Optimize Queries**: When it comes to optimizing database queries, make sure to limit the amount of data that gets returned from a query by using the SELECT statement effectively. Avoid using "SELECT *". Also, use JOINs effectively and avoid unnecessary subqueries. Make use of indexes where possible, but don't over-index as it may lead to slower write operations.

4. **Use Prepared Statements**: Prepared statements or parameterized queries are a way of executing SQL statements with parameters that help prevent SQL injection attacks. They also allow the database to cache the queries for improved performance.

5. **Connection and Memory Management**: Ensure to close database connections when not in use. Also, pay attention to managing the memory resources efficiently. For instance, avoid loading large amounts of data into memory at once, process data in chunks if possible.

6. **Concurrency Control**: Implement proper concurrency control mechanisms to ensure data integrity and consistency when multiple processes are interacting with the database concurrently.

7. **Profiling and monitoring**: Regularly profile your database and monitor the performance. This can help you identify potential bottlenecks and areas for improvement.

As always, the specific techniques and strategies you use will depend on your specific use case, the database system you're using, and the nature of your data and queries.

=== System Statistics ===

â†’ Querying database statistics...
  â€¢ Using find_all() helper - simplified query API

ğŸ“Š Database Statistics:
  â€¢ Total conversations: 4
  â€¢ Total messages stored: 14
  â€¢ All messages indexed for vector search âœ“
  â€¢ All messages indexed for text search âœ“
  â€¢ All messages queryable by metadata âœ“

=== Step 8: Dynamic Search Configuration ===
Each conversation can have its own search config...

ğŸ’¡ Conversations can store custom search configurations:
  â€¢ Search type: hybrid, text, or vector
  â€¢ Relevance thresholds
  â€¢ Filter by tags or metadata
  â€¢ Collection-specific settings
  â€¢ Per-conversation AI behavior

This enables context-aware search tuned to each conversation's needs!


=== Cleanup ===
Deleting example collections...

âœ… All done! RAG system demonstrated successfully.

âœ“ Using search results to enhance AI responses (RAG)
âœ“ Building a self-improving knowledge base
âœ“ Dynamic search configurations per conversation

ekoDB provides everything needed for AI-powered applications:
  â€¢ Vector search (semantic similarity)
  â€¢ Text search (keyword matching)
  â€¢ Hybrid search (best of both)
  â€¢ AI functions (Chat, Embed)
  â€¢ Flexible querying and filtering
  â€¢ All in one database - no external dependencies!


[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m
[36mRunning Python RAG Example...[0m
[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m
=== ekoDB RAG Conversation System ===

This example shows how ekoDB can power a self-improving AI system
that learns from its own conversation history.

=== Step 1: Building Conversation History ===
Storing previous conversations with embeddings...

  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 34 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.230s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 169 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.304s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 33 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.459s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 230 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.287s
    â€¢ Function auto-cleaned up by client
âœ“ Stored Rust programming conversation (4 messages)
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 31 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.298s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 217 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.213s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 33 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.482s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 232 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.270s
    â€¢ Function auto-cleaned up by client
âœ“ Stored database design conversation (4 messages)
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 36 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.728s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 178 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.312s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 37 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.263s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 213 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.259s
    â€¢ Function auto-cleaned up by client
âœ“ Stored performance optimization conversation (4 messages)

=== Step 2: New User Question with Context Retrieval ===
User asks: "How do I write memory-safe high-performance database code?"

=== Step 3: Searching Related Context ===
Using hybrid search to find relevant messages from all conversations...


â†’ Generating embedding for user question...
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 58 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.282s
    â€¢ Function auto-cleaned up by client

â†’ Executing hybrid_search()...
  â€¢ Collection: rag_messages
  â€¢ Query text: "How do I write memory-safe high-performance database code?"
  â€¢ Vector dimensions: 1536
  â€¢ Limit: 5 results
  â€¢ Search type: Semantic (vector) + Keyword (text)
  â€¢ Server combines both scores for relevance ranking
  âœ“ Search completed in 0.102s

âœ“ Found 5 related messages across all conversations:
  1. [Score: 0.000] From conv_database_design
     Use NoSQL when you need: flexible schemas, horizontal scaling, high write throughput, or when working with unstructured data. SQL is better for complex queries, ACID transactions, and structured data with well-defined relationships.

  2. [Score: 0.000] From conv_database_design
     What is database normalization?

  3. [Score: 0.000] From conv_database_design
     Database normalization is the process of organizing data to reduce redundancy and improve data integrity. It involves dividing large tables into smaller ones and defining relationships between them using foreign keys.

  4. [Score: 0.000] From conv_database_design
     When should I use NoSQL over SQL?

  5. [Score: 0.000] From conv_performance
     How can I optimize database queries?

=== Step 4: Generating Context-Aware Response ===
âœ“ AI Response (with context from 3 conversations):

Writing memory-safe high-performance database code involves several strategies:

1. **Choose the right database system**: Depending on your data structure and use case, the choice of SQL or NoSQL can significantly impact performance. As mentioned earlier, use NoSQL for flexible schemas, horizontal scaling, high write throughput, or unstructured data. SQL is better for complex queries, ACID transactions, and structured data with well-defined relationships.

2. **Normalization**: As discussed earlier, database normalization is a process that helps reduce data redundancy and improve data integrity. This can result in efficient memory usage and improved performance.

3. **Optimize queries**: The performance of database code can largely depend on how efficiently queries are written and executed. Query optimization techniques include using indexes effectively, avoiding full table scans by using WHERE clause, choosing SELECT statements carefully to avoid unnecessary columns, and using JOIN clauses effectively.

4. **Memory management**: In terms of memory safety, you should ensure to free up memory that's no longer needed, avoid memory leaks, and handle exceptions that could potentially cause memory issues. Use built-in database features for memory management and follow best coding practices for the language you're using.

5. **Use connection pools**: Connection pooling can greatly enhance the performance of your database code. It reduces the overhead of creating a new connection for every database request.

6. **Batch processing**: Instead of writing or reading one record at a time, batch processing allows you to write or read many records at once, which can improve performance.

Remember, it's often a trade-off between memory usage and performance. It's important to test and monitor your system to ensure it's operating optimally.

=== Step 5: Storing New Conversation ===
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 58 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.282s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 1856 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.317s
    â€¢ Function auto-cleaned up by client
âœ“ New conversation stored and indexed for future retrieval

=== Step 6: Cross-Conversation Search ===
Searching for messages about 'ownership' across ALL conversations...

âœ“ Found 3 messages mentioning ownership:
  1. From conv_rust_programming: Rust's key features include: memory safety without garbage collection, zero-cost abstractions, ownership system, powerful type system, and excellent concurrency support.

  2. From conv_performance: Rust's ownership system provides zero-cost memory management. Use Box for heap allocation, Rc/Arc for shared ownership, and avoid cloning large data structures. The compiler optimizes away unnecessary allocations.

  3. From conv_new_question: Writing memory-safe high-performance database code involves several strategies:

1. **Choose the right database system**: Depending on your data structure and use case, the choice of SQL or NoSQL can significantly impact performance. As mentioned earlier, use NoSQL for flexible schemas, horizontal scaling, high write throughput, or unstructured data. SQL is better for complex queries, ACID transactions, and structured data with well-defined relationships.

2. **Normalization**: As discussed earlier, database normalization is a process that helps reduce data redundancy and improve data integrity. This can result in efficient memory usage and improved performance.

3. **Optimize queries**: The performance of database code can largely depend on how efficiently queries are written and executed. Query optimization techniques include using indexes effectively, avoiding full table scans by using WHERE clause, choosing SELECT statements carefully to avoid unnecessary columns, and using JOIN clauses effectively.

4. **Memory management**: In terms of memory safety, you should ensure to free up memory that's no longer needed, avoid memory leaks, and handle exceptions that could potentially cause memory issues. Use built-in database features for memory management and follow best coding practices for the language you're using.

5. **Use connection pools**: Connection pooling can greatly enhance the performance of your database code. It reduces the overhead of creating a new connection for every database request.

6. **Batch processing**: Instead of writing or reading one record at a time, batch processing allows you to write or read many records at once, which can improve performance.

Remember, it's often a trade-off between memory usage and performance. It's important to test and monitor your system to ensure it's operating optimally.

=== System Statistics ===
Total conversations: 4
Total messages stored: 14
All messages are indexed for vector search âœ“
All messages are indexed for text search âœ“
All messages are queryable by metadata âœ“

=== Step 8: Dynamic Search Configuration ===
Each conversation can have its own search config...

ğŸ’¡ Conversations can store custom search configurations:
  â€¢ Search type: hybrid, text, or vector
  â€¢ Relevance thresholds
  â€¢ Filter by tags or metadata
  â€¢ Collection-specific settings
  â€¢ Per-conversation AI behavior

This enables context-aware search tuned to each conversation's needs!

=== Cleanup ===
âœ“ Cleanup complete


=== ğŸ“š Summary: What This Example Showed ===

ğŸ”§ ekoDB Native Capabilities Used:
  âœ“ Functions with Embed operation (AI integration)
  âœ“ Hybrid Search (text + vector combined)
  âœ“ Text Search (full-text with stemming)
  âœ“ Automatic embedding generation
  âœ“ Cross-collection queries

ğŸš€ New Client Helper Methods:
  â€¢ client.embed(text, model) - Generate embeddings
  â€¢ client.hybrid_search() - Semantic + keyword search
  â€¢ client.text_search() - Full-text search
  â€¢ client.find_all() - Query all documents

ğŸ’¡ Key Takeaways:
  1. ekoDB handles AI Functions natively - no external services needed
  2. One-line embedding generation with auto-cleanup
  3. Hybrid search combines semantic understanding + keyword matching
  4. Perfect for RAG: store, search, and retrieve context
  5. All AI capabilities accessible through simple client methods

ğŸ¯ Build production RAG systems with ekoDB!
   â†’ Set OPENAI_API_KEY in your ekoDB server environment
   â†’ Use these client helpers to make AI integration simple
   â†’ Scale to millions of documents with native indexing


[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m
[36mRunning TypeScript RAG Example...[0m
[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m
=== ekoDB RAG Conversation System ===

This example shows how ekoDB can power a self-improving AI system
that learns from its own conversation history.

=== Step 1: Building Conversation History ===
Storing previous conversations with embeddings...

  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 34 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.274s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 169 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.322s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 33 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.356s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 230 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.277s
    â€¢ Function auto-cleaned up by client
âœ“ Stored Rust programming conversation (4 messages)
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 31 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.228s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 217 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.259s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 33 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.369s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 232 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.419s
    â€¢ Function auto-cleaned up by client
âœ“ Stored database design conversation (4 messages)
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 36 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.389s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 178 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.307s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 37 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.263s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 213 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.301s
    â€¢ Function auto-cleaned up by client
âœ“ Stored performance optimization conversation (4 messages)

=== Step 2: New User Question with Context Retrieval ===
User asks: "How do I write memory-safe high-performance database code?"

=== Step 3: Searching Related Context ===
Using hybrid search to find relevant messages from all conversations...


â†’ Generating embedding for user question...
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 58 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.222s
    â€¢ Function auto-cleaned up by client

â†’ Executing hybridSearch()...
  â€¢ Collection: rag_messages
  â€¢ Query text: "How do I write memory-safe high-performance database code?"
  â€¢ Vector dimensions: 1536
  â€¢ Limit: 5 results
  â€¢ Search type: Semantic (vector) + Keyword (text)
  â€¢ Server combines both scores for relevance ranking
  âœ“ Search completed in 0.076s
âœ“ Found 5 related messages across all conversations:
  1. [Score: 0.000] From conv_database_design
     Database normalization is the process of organizing data to reduce redundancy and improve data integrity. It involves dividing large tables into smaller ones and defining relationships between them using foreign keys.

  2. [Score: 0.000] From conv_database_design
     Use NoSQL when you need: flexible schemas, horizontal scaling, high write throughput, or when working with unstructured data. SQL is better for complex queries, ACID transactions, and structured data with well-defined relationships.

  3. [Score: 0.000] From conv_database_design
     What is database normalization?

  4. [Score: 0.000] From conv_database_design
     When should I use NoSQL over SQL?

  5. [Score: 0.000] From conv_performance
     How can I optimize database queries?

=== Step 4: Generating Context-Aware Response ===
âœ“ AI Response (with context from 3 conversations):

Writing memory-safe, high-performance database code involves several considerations:

1. Use the Right Database Type: Depending on your specific use case, you might require a SQL or NoSQL database. SQL databases are suitable for structured data with complex queries and ACID transactions. On the other hand, NoSQL databases are suitable for high write throughput, horizontal scaling, flexible schemas, and handling unstructured data.

2. Normalization: Database normalization helps to reduce redundancy and improve data integrity. It involves dividing large tables into smaller ones and defining relationships between them using foreign keys. Using normalization techniques, you can optimize your database structure for better performance.

3. Query Optimization: The way you write your queries can significantly impact performance. Avoid using SELECT * in your queries; instead, specify the columns you need. Use JOINs effectively and avoid N+1 queries. Also, making use of indexing can significantly speed up data retrieval times.

4. Efficient Memory Management: To ensure memory safety, handle database connections carefully. Make sure to close connections when they're no longer needed to prevent memory leaks. If you're using an ORM, be aware of lazy loading and eager loading and use them judiciously to avoid unnecessary memory usage.

5. Regular Monitoring and Optimization: Regularly check the performance of your database using performance monitoring tools. This can help you identify slow queries and areas where you can optimize for better performance. 

6. Concurrent Transactions: Be mindful of locks and transactions that can impact performance. Try to minimize lock contention where possible.

Remember, the specific techniques you use might depend on the programming language and the database system you're using. Always follow the best practices recommended by the database system documentation.

=== Step 5: Storing New Conversation ===
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 58 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.348s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 1914 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.273s
    â€¢ Function auto-cleaned up by client
âœ“ New conversation stored and indexed for future retrieval

=== Step 6: Cross-Conversation Search ===
Searching for messages about 'ownership' across ALL conversations...


â†’ Executing textSearch()...
  â€¢ Collection: rag_messages
  â€¢ Query: "ownership system"
  â€¢ Limit: 3 results
  â€¢ Search method: Full-text with fuzzy matching & stemming
  â€¢ No vector embeddings needed - pure keyword search
  âœ“ Text search completed in 0.059s
âœ“ Found 3 messages mentioning ownership:
  1. From conv_rust_programming: Rust's key features include: memory safety without garbage collection, zero-cost abstractions, ownership system, powerful type system, and excellent concurrency support.

  2. From conv_performance: Rust's ownership system provides zero-cost memory management. Use Box for heap allocation, Rc/Arc for shared ownership, and avoid cloning large data structures. The compiler optimizes away unnecessary allocations.

  3. From conv_rust_programming: The borrow checker enforces Rust's ownership rules at compile time. It ensures that references don't outlive the data they point to and prevents data races by allowing either multiple immutable references or one mutable reference.

=== System Statistics ===

â†’ Querying database statistics...
  â€¢ Using findAllWithLimit() helper - simplified query API

ğŸ“Š Database Statistics:
  â€¢ Total conversations: 4
  â€¢ Total messages stored: 14
  â€¢ All messages indexed for vector search âœ“
  â€¢ All messages indexed for text search âœ“
  â€¢ All messages queryable by metadata âœ“

=== Step 8: Dynamic Search Configuration ===
Each conversation can have its own search config...

ğŸ’¡ Conversations can store custom search configurations:
  â€¢ Search type: hybrid, text, or vector
  â€¢ Relevance thresholds
  â€¢ Filter by tags or metadata
  â€¢ Collection-specific settings
  â€¢ Per-conversation AI behavior

This enables context-aware search tuned to each conversation's needs!

=== Cleanup ===
âœ“ Cleanup complete


=== ğŸ“š Summary: What This Example Showed ===

ğŸ”§ ekoDB Native Capabilities Used:
  âœ“ Functions with Embed operation (AI integration)
  âœ“ Hybrid Search (text + vector combined)
  âœ“ Text Search (full-text with stemming)
  âœ“ Automatic embedding generation
  âœ“ Cross-collection queries

ğŸš€ New Client Helper Methods:
  â€¢ client.embed(text, model) - Generate embeddings
  â€¢ client.hybridSearch() - Semantic + keyword search
  â€¢ client.textSearch() - Full-text search
  â€¢ client.findAllWithLimit() - Query all documents

ğŸ’¡ Key Takeaways:
  1. ekoDB handles AI Functions natively - no external services needed
  2. One-line embedding generation with auto-cleanup
  3. Hybrid search combines semantic understanding + keyword matching
  4. Perfect for RAG: store, search, and retrieve context
  5. All AI capabilities accessible through simple client methods

ğŸ¯ Build production RAG systems with ekoDB!
   â†’ Set OPENAI_API_KEY in your ekoDB server environment
   â†’ Use these client helpers to make AI integration simple
   â†’ Scale to millions of documents with native indexing


[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m
[36mRunning Go RAG Example...[0m
[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m
=== ekoDB RAG Conversation System ===

This example shows how ekoDB can power a self-improving AI system
that learns from its own conversation history.

=== Step 1: Building Conversation History ===
Storing previous conversations with embeddings...

  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 34 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.245s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 169 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.437s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 33 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.308s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 230 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.229s
    â€¢ Function auto-cleaned up by client
âœ“ Stored Rust programming conversation (4 messages)
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 31 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.291s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 217 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.444s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 33 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.271s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 232 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.299s
    â€¢ Function auto-cleaned up by client
âœ“ Stored database design conversation (4 messages)
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 36 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.245s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 178 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.291s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 37 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.280s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 213 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.306s
    â€¢ Function auto-cleaned up by client
âœ“ Stored performance optimization conversation (4 messages)

=== Step 2: New User Question with Context Retrieval ===
User asks: "How do I write memory-safe high-performance database code?"

=== Step 3: Searching Related Context ===
Using hybrid search to find relevant messages from all conversations...


â†’ Generating embedding for user question...
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 58 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 1.105s
    â€¢ Function auto-cleaned up by client

â†’ Executing HybridSearch()...
  â€¢ Collection: rag_messages
  â€¢ Query text: "How do I write memory-safe high-performance database code?"
  â€¢ Vector dimensions: 1536
  â€¢ Limit: 5 results
  â€¢ Search type: Semantic (vector) + Keyword (text)
  â€¢ Server combines both scores for relevance ranking
  âœ“ Search completed in 0.096s

âœ“ Found 5 related messages across all conversations:
  1. [Score: 0.000] From conv_performance
     How can I optimize database queries?

  2. [Score: 0.000] From conv_database_design
     Use NoSQL when you need: flexible schemas, horizontal scaling, high write throughput, or when working with unstructured data. SQL is better for complex queries, ACID transactions, and structured data with well-defined relationships.

  3. [Score: 0.000] From conv_database_design
     When should I use NoSQL over SQL?

  4. [Score: 0.000] From conv_database_design
     What is database normalization?

  5. [Score: 0.000] From conv_database_design
     Database normalization is the process of organizing data to reduce redundancy and improve data integrity. It involves dividing large tables into smaller ones and defining relationships between them using foreign keys.

=== Step 4: Generating Context-Aware Response ===
âœ“ AI Response (with context from 3 conversations):

Writing memory-safe, high-performance database code involves several practices:

1. **Optimization of Queries:** As discussed in Context 1, optimizing your database queries is a key step towards high-performance database code. This can involve practices such as using indexing, limiting the amount of data retrieved from a query, avoiding nested queries, and using joins appropriately.

2. **Choice of Database System:** Based on Context 2 and 3, the choice between SQL and NoSQL can impact the performance and memory usage of your code. NoSQL databases can be more efficient for unstructured data and high write throughput, while SQL can be better for complex queries and structured data. 

3. **Normalization:** As mentioned in Context 4 and 5, database normalization is a process that can help improve data integrity and reduce redundancy. This can contribute to the efficiency of your database operations and thus the performance of your code.

4. **Memory Management:** In addition to the above, you should pay attention to the memory management in your own code. This includes properly closing database connections after use, cleaning up any temporary data structures, and being mindful of the data types and structures you use.

5. **Profiling and Monitoring:** Use profiling tools to monitor the performance of your database code. Identify bottlenecks, slow queries, and memory leaks. Use this information to refine and optimize your code.

6. **Concurrency and Parallelism:** Depending on the database system and the programming language you are using, you can leverage concurrency or parallelism to improve the performance of your code. Make sure to handle synchronization and avoid race conditions to keep your code memory-safe.

Remember, each database and application is unique, so what works best will depend on your specific circumstances. Always test different solutions to see what gives the best results.

=== Step 5: Storing New Conversation ===
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 58 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.297s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB Embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 1922 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.251s
    â€¢ Function auto-cleaned up by client
âœ“ New conversation stored and indexed for future retrieval

=== Step 6: Cross-Conversation Search ===
Searching for messages about 'ownership' across ALL conversations...


â†’ Executing TextSearch()...
  â€¢ Collection: rag_messages
  â€¢ Query: "ownership system"
  â€¢ Limit: 3 results
  â€¢ Search method: Full-text with fuzzy matching & stemming
  â€¢ No vector embeddings needed - pure keyword search
  âœ“ Text search completed in 0.059s

âœ“ Found 3 messages mentioning ownership:
  1. From conv_rust_programming: Rust's key features include: memory safety without garbage collection, zero-cost abstractions, ownership system, powerful type system, and excellent concurrency support.

  2. From conv_performance: Rust's ownership system provides zero-cost memory management. Use Box for heap allocation, Rc/Arc for shared ownership, and avoid cloning large data structures. The compiler optimizes away unnecessary allocations.

  3. From conv_rust_programming: The borrow checker enforces Rust's ownership rules at compile time. It ensures that references don't outlive the data they point to and prevents data races by allowing either multiple immutable references or one mutable reference.

=== System Statistics ===

â†’ Querying database statistics...
  â€¢ Using FindAll() helper - simplified query API

ğŸ“Š Database Statistics:
  â€¢ Total conversations: 4
  â€¢ Total messages stored: 14
  â€¢ All messages indexed for vector search âœ“
  â€¢ All messages indexed for text search âœ“
  â€¢ All messages queryable by metadata âœ“

=== Step 8: Dynamic Search Configuration ===
Each conversation can have its own search config...

ğŸ’¡ Conversations can store custom search configurations:
  â€¢ Search type: hybrid, text, or vector
  â€¢ Relevance thresholds
  â€¢ Filter by tags or metadata
  â€¢ Collection-specific settings
  â€¢ Per-conversation AI behavior

This enables context-aware search tuned to each conversation's needs!

=== Cleanup ===
âœ“ Cleanup complete


=== ğŸ“š Summary: What This Example Showed ===

ğŸ”§ ekoDB Native Capabilities Used:
  âœ“ Functions with Embed operation (AI integration)
  âœ“ Hybrid Search (text + vector combined)
  âœ“ Text Search (full-text with stemming)
  âœ“ Automatic embedding generation
  âœ“ Cross-collection queries

ğŸš€ New Client Helper Methods:
  â€¢ client.Embed(text, model) - Generate embeddings
  â€¢ client.HybridSearch() - Semantic + keyword search
  â€¢ client.TextSearch() - Full-text search
  â€¢ client.FindAll() - Query all documents

ğŸ’¡ Key Takeaways:
  1. ekoDB handles AI Functions natively - no external services needed
  2. One-line embedding generation with auto-cleanup
  3. Hybrid search combines semantic understanding + keyword matching
  4. Perfect for RAG: store, search, and retrieve context
  5. All AI capabilities accessible through simple client methods

ğŸ¯ Build production RAG systems with ekoDB!
   â†’ Set OPENAI_API_KEY in your ekoDB server environment
   â†’ Use these client helpers to make AI integration simple
   â†’ Scale to millions of documents with native indexing


[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m
[36mRunning Kotlin RAG Example...[0m
[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m
=== ekoDB RAG Conversation System ===

This example shows how ekoDB can power a self-improving AI system
that learns from its own conversation history.

SLF4J(W): No SLF4J providers were found.
SLF4J(W): Defaulting to no-operation (NOP) logger implementation
SLF4J(W): See https://www.slf4j.org/codes.html#noProviders for further details.
=== Step 1: Building Conversation History ===
Storing previous conversations with embeddings...

  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 34 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.371s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 169 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.426s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 33 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.269s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 230 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.287s
    â€¢ Function auto-cleaned up by client
âœ“ Stored Rust programming conversation (4 messages)
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 31 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.343s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 217 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.374s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 33 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.287s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 232 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.293s
    â€¢ Function auto-cleaned up by client
âœ“ Stored database design conversation (4 messages)
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 36 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.324s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 178 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.522s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 37 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.504s
    â€¢ Function auto-cleaned up by client
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 213 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.273s
    â€¢ Function auto-cleaned up by client
âœ“ Stored performance optimization conversation (4 messages)

=== Step 2: New User Question with Context Retrieval ===
User asks: "How do I write memory-safe high-performance database code?"

=== Step 3: Searching Related Context ===
Using hybrid search to find relevant messages from all conversations...


â†’ Generating embedding for user question...
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 58 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.299s
    â€¢ Function auto-cleaned up by client

â†’ Executing hybridSearch()...
  â€¢ Collection: rag_messages
  â€¢ Query text: "How do I write memory-safe high-performance database code?"
  â€¢ Vector dimensions: 1536
  â€¢ Limit: 5 results
  â€¢ Search type: Semantic (vector) + Keyword (text)
  â€¢ Server combines both scores for relevance ranking
  âœ“ Search completed in 0.114s

âœ“ Found 5 related messages across all conversations:
  1. [Score: 0.000] From conv_database_design
     Database normalization is the process of organizing data to reduce redundancy and improve data integrity. It involves dividing large tables into smaller ones and defining relationships between them using foreign keys.

  2. [Score: 0.000] From conv_database_design
     What is database normalization?

  3. [Score: 0.000] From conv_database_design
     Use NoSQL when you need: flexible schemas, horizontal scaling, high write throughput, or when working with unstructured data. SQL is better for complex queries, ACID transactions, and structured data with well-defined relationships.

  4. [Score: 0.000] From conv_database_design
     When should I use NoSQL over SQL?

  5. [Score: 0.000] From conv_performance
     How can I optimize database queries?

=== Step 4: Generating Context-Aware Response ===
âœ“ Context prepared from search results
âœ“ AI would use this context to generate comprehensive response

=== Step 5: Storing New Conversation ===
  â†’ Calling ekoDB embed() helper...
    â€¢ Using model: text-embedding-3-small
    â€¢ Text length: 58 characters
    â€¢ Behind the scenes: Creating temp Function with Embed operation
    âœ“ Generated embedding: 1536 dimensions in 0.354s
    â€¢ Function auto-cleaned up by client
âœ“ New conversation stored and indexed for future retrieval

=== Step 6: Cross-Conversation Search ===
Searching for messages about 'ownership' across ALL conversations...


â†’ Executing textSearch()...
  â€¢ Collection: rag_messages
  â€¢ Query: "ownership system"
  â€¢ Limit: 3 results
  â€¢ Search method: Full-text with fuzzy matching & stemming
  â€¢ No vector embeddings needed - pure keyword search
  âœ“ Text search completed in 0.058s

âœ“ Found 3 messages mentioning ownership:
  1. From conv_performance: Rust's ownership system provides zero-cost memory management. Use Box for heap allocation, Rc/Arc for shared ownership, and avoid cloning large data structures. The compiler optimizes away unnecessary allocations.

  2. From conv_rust_programming: Rust's key features include: memory safety without garbage collection, zero-cost abstractions, ownership system, powerful type system, and excellent concurrency support.

  3. From conv_rust_programming: The borrow checker enforces Rust's ownership rules at compile time. It ensures that references don't outlive the data they point to and prevents data races by allowing either multiple immutable references or one mutable reference.

=== System Statistics ===

â†’ Querying database statistics...
  â€¢ Using findAllWithLimit() helper - simplified query API

ğŸ“Š Database Statistics:
  â€¢ Total conversations: 4
  â€¢ Total messages stored: 13
  â€¢ All messages indexed for vector search âœ“
  â€¢ All messages indexed for text search âœ“
  â€¢ All messages queryable by metadata âœ“

=== Step 8: Dynamic Search Configuration ===
Each conversation can have its own search config...

ğŸ’¡ Conversations can store custom search configurations:
  â€¢ Search type: hybrid, text, or vector
  â€¢ Relevance thresholds
  â€¢ Filter by tags or metadata
  â€¢ Collection-specific settings
  â€¢ Per-conversation AI behavior

This enables context-aware search tuned to each conversation's needs!

=== Cleanup ===
âœ“ Cleanup complete


=== ğŸ“š Summary: What This Example Showed ===

ğŸ”§ ekoDB Native Capabilities Used:
  âœ“ Functions with Embed operation (AI integration)
  âœ“ Hybrid Search (text + vector combined)
  âœ“ Text Search (full-text with stemming)
  âœ“ Automatic embedding generation
  âœ“ Cross-collection queries

ğŸš€ New Client Helper Methods:
  â€¢ client.embed(text, model) - Generate embeddings
  â€¢ client.hybridSearch() - Semantic + keyword search
  â€¢ client.textSearch() - Full-text search
  â€¢ client.findAllWithLimit() - Query all documents

ğŸ’¡ Key Takeaways:
  1. ekoDB handles AI Functions natively - no external services needed
  2. One-line embedding generation with auto-cleanup
  3. Hybrid search combines semantic understanding + keyword matching
  4. Perfect for RAG: store, search, and retrieve context
  5. All AI capabilities accessible through simple client methods

ğŸ¯ Build production RAG systems with ekoDB!
   â†’ Set OPENAI_API_KEY in your ekoDB server environment
   â†’ Use these client helpers to make AI integration simple
   â†’ Scale to millions of documents with native indexing


[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m
âœ… [32mRAG Examples Complete![0m
[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m

[32mWhat you just saw across 5 languages:[0m
  âœ“ Embeddings generated via ekoDB Functions
  âœ“ Hybrid search (semantic + keyword)
  âœ“ Text search with stemming
  âœ“ Cross-conversation context retrieval
  âœ“ Simple client helpers wrapping powerful AI

[36mMission: AI for All ğŸš€[0m - Making RAG accessible to everyone!

